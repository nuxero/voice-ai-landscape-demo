services:
  pipecat-agent:
    build: .
    ports:
      - "7860:7860"
    environment:
      - SPEACHES_BASE_URL=http://speaches:8000
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      - STT_MODEL=${STT_MODEL:-Systran/faster-distil-whisper-small.en}
      - TTS_MODEL=${TTS_MODEL:-speaches-ai/Kokoro-82M-v1.0-ONNX}
      - TTS_VOICE=${TTS_VOICE:-af_heart}
      - SERVER_HOST=${SERVER_HOST:-0.0.0.0}
      - SERVER_PORT=${SERVER_PORT:-7860}
      - SYSTEM_INSTRUCTION=${SYSTEM_INSTRUCTION:-You are a helpful voice assistant.}
    depends_on:
      - speaches
      - ollama
    networks:
      - voice-agent-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    networks:
      - voice-agent-network
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

include:
  - path: ./speaches/compose.${SPEACHES_MODE:-cpu}.yaml
    env_file: .env

networks:
  voice-agent-network:
    driver: bridge

volumes:
  speaches-models:
    driver: local
  ollama-models:
    driver: local
